{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mido\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mido\n",
    "\n",
    "def createMidiFileWithAllMessages(notes, duration=200, wait_time = 0, filename='test.mid'):\n",
    "    mid = mido.MidiFile()\n",
    "    track = mido.MidiTrack()\n",
    "    mid.tracks.append(track)\n",
    "\n",
    "    for note in notes:\n",
    "        track.append(mido.Message('note_on', note=note, velocity=64, time=wait_time))\n",
    "        track.append(mido.Message('note_off', note=note, velocity=0, time=duration))\n",
    "\n",
    "    mid.save(filename.removesuffix('.mid') + '.mid')\n",
    "\n",
    "\n",
    "notes = range(50, 80) \n",
    "\n",
    "createMidiFileWithAllMessages(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "catch all the data\n",
      "['data\\\\albeniz\\\\alb_esp1.mid', 'data\\\\albeniz\\\\alb_esp2.mid', 'data\\\\albeniz\\\\alb_esp3.mid', 'data\\\\albeniz\\\\alb_esp4.mid', 'data\\\\albeniz\\\\alb_esp5.mid', 'data\\\\albeniz\\\\alb_esp6.mid', 'data\\\\albeniz\\\\alb_se1.mid', 'data\\\\albeniz\\\\alb_se2.mid', 'data\\\\albeniz\\\\alb_se3.mid', 'data\\\\albeniz\\\\alb_se4.mid']\n",
      "295\n"
     ]
    }
   ],
   "source": [
    "print('catch all the data')\n",
    "\n",
    "def get_midis():\n",
    "    ms = []\n",
    "    directory = \"data\"\n",
    "    for foldername in os.listdir(directory):\n",
    "        directory = os.path.join(\"data\", foldername)\n",
    "        for filename in os.listdir(directory):\n",
    "            if('V2'in filename): continue\n",
    "            if os.path.isfile(os.path.join(directory, filename)):\n",
    "                ms.append(os.path.join(directory, filename))\n",
    "                # print(filename)\n",
    "    return ms\n",
    "\n",
    "midis = get_midis()\n",
    "print(midis[:10])\n",
    "# works only with files with just one track\n",
    "def get_all_notes_one_file(midi_file):\n",
    "    file = mido.MidiFile(midi_file)\n",
    "    track = file.tracks[1]\n",
    "    messages = []\n",
    "    for message in track:\n",
    "        if(message.type == 'note_on'):\n",
    "            messages.append(message)\n",
    "    \n",
    "    notes = [0] + [m.note for m in messages] + [1]\n",
    "    # print(notes)\n",
    "    return notes\n",
    "\n",
    "all_notes_all_files = [get_all_notes_one_file(m) for m in midis]\n",
    "\n",
    "print(len(all_notes_all_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(763088,)\n",
      "notes extreme to remove :  [ 24  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  42 104\n",
      " 105 106 107]\n",
      "[ 0 41 41 48 48 46 46 48 48 46]\n"
     ]
    }
   ],
   "source": [
    "X_values = np.concatenate(all_notes_all_files)\n",
    "print(X_values.shape)\n",
    "\n",
    "# notes\n",
    "\n",
    "n = np.unique(X_values, return_counts=True)\n",
    "notes_extreme = n[0][n[1] < 100]\n",
    "print('notes extreme to remove : ', notes_extreme)\n",
    "X_values = X_values[~np.isin(X_values, notes_extreme)]\n",
    "\n",
    "nunique = np.unique(X_values, return_counts=True)\n",
    "\n",
    "# Tokenize the data\n",
    "\n",
    "tokenToVals = nunique[0]\n",
    "\n",
    "ValsToToken = {v:i for i, v in enumerate(tokenToVals)}\n",
    "vocab_size = len(tokenToVals)\n",
    "\n",
    "X = np.array([ValsToToken[x] for x in X_values])\n",
    "a = np.random.randint(0, len(tokenToVals), 10)\n",
    "\n",
    "print(X[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "block_size = 128\n",
    "batch_size = 64\n",
    "n_embd = 192 # be a multiple of n_head\n",
    "dropout = 0.2\n",
    "n_heads = 6 # be a divisible of n_embd\n",
    "vocab_size = len(tokenToVals) # ~= 1800\n",
    "n_layer = 4\n",
    "learning_rate = 0.05\n",
    "eval_iters = 100\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([ValsToToken[x] for x in X_values], dtype=torch.long, device=device)\n",
    "n = int(0.9*len(X))\n",
    "X_train = X[:n]\n",
    "X_val = X[n:]\n",
    "\n",
    "# Single head self-attention\n",
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input of size (batch, time-step, channels)\n",
    "        # output of size (batch, time-step, head size)\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,hs)\n",
    "        q = self.query(x) # (B,T,hs)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,hs)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
    "        return out\n",
    "# multi-head self-attention\n",
    "class MultiHead(nn.Module):\n",
    "    \"\"\" multi-head self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, n_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(n_heads)])\n",
    "        self.proj = nn.Linear(n_heads * head_size, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # input of size (batch, time-step, channels)\n",
    "        # output of size (batch, time-step, channels)\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "# feed-forward layer\n",
    "class FeedForward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "    \n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, n_embd * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_embd * 4, n_embd),\n",
    "            nn.Dropout()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        return out\n",
    "# block\n",
    "class Block(nn.Module):\n",
    "    \"\"\" a transformer Block \"\"\"\n",
    "    \n",
    "    def __init__(self, n_embd, n_head):\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.MultiHeads = MultiHead(n_heads, head_size)\n",
    "        self.ffwd = FeedForward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.MultiHeads(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "# transformer\n",
    "class Transformer(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_heads) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd)\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "        \n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "        \n",
    "    def forward(self, idx, targets=None):\n",
    "        # print('oouais', idx.shape)\n",
    "        B, T = idx.shape\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        # pos_emb = self.position_embedding_table(torch.arange(T)) # (T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "    \n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -block_size:] # (B, T)\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "\n",
    "model = Transformer()\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = X_train if split == 'train' else X_val\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            # print(X.shape,Y.shape)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    # print(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1826752 parameters\n",
      "0.05\n",
      "step 0: train loss 3.0295, val loss 3.0810\n",
      "0.05\n",
      "step 5000: train loss 3.2652, val loss 3.2703\n",
      "0.05\n",
      "step 10000: train loss 3.3494, val loss 3.3348\n",
      "0.05\n",
      "step 15000: train loss 3.1571, val loss 3.2143\n",
      "0.04000000000000001\n",
      "step 20000: train loss 3.1908, val loss 3.2299\n",
      "0.04000000000000001\n",
      "step 25000: train loss 3.2416, val loss 3.2459\n",
      "0.04000000000000001\n",
      "step 30000: train loss 3.3269, val loss 3.3400\n",
      "0.04000000000000001\n",
      "step 35000: train loss 3.3257, val loss 3.3574\n",
      "0.03200000000000001\n",
      "step 40000: train loss 3.1948, val loss 3.2389\n",
      "0.03200000000000001\n",
      "step 45000: train loss 3.3689, val loss 3.3771\n",
      "0.03200000000000001\n",
      "step 50000: train loss 3.0971, val loss 3.1716\n",
      "0.03200000000000001\n",
      "step 55000: train loss 3.2110, val loss 3.2647\n",
      "0.025600000000000008\n",
      "step 60000: train loss 3.0800, val loss 3.1038\n",
      "0.025600000000000008\n",
      "step 65000: train loss 3.2188, val loss 3.2285\n",
      "0.025600000000000008\n",
      "step 70000: train loss 3.2413, val loss 3.2302\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m logits, loss \u001b[38;5;241m=\u001b[39m model(xb, yb)\n\u001b[0;32m     26\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 27\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     29\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\lorra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lorra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "max_iters = 10000\n",
    "eval_interval = 500\n",
    "lossi = []\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters()), 'parameters')\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=2000, gamma=0.3)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        print(optimizer.param_groups[0]['lr'])\n",
    "        losses = estimate_loss()\n",
    "        lossi.append(losses)\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "\n",
    "# save the model\n",
    "torch.save(model.state_dict(), 'model1.pth')\n",
    "\n",
    "print(lossi)\n",
    "plt.plot([l['train'] for l in lossi], label='train')\n",
    "plt.plot([l['val'] for l in lossi], label='val')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# converting it back to music\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 65, 71, 74, 75, 73, 65, 86, 84, 72, 68, 75, 75, 75, 75, 80, 73, 85, 67, 72, 78, 75, 82, 63, 69, 73, 75, 65, 70, 80, 72, 87, 80, 84, 63, 70, 78, 83, 74, 82, 83, 87, 76, 77, 84, 76, 76, 80, 75, 90, 67, 83, 69, 74, 80, 70, 75, 81, 89, 79, 89, 84, 86, 91, 63, 75, 89, 71, 68, 78, 87, 85, 89, 77, 71, 84, 92, 72, 97, 94, 88, 75, 88, 79, 87, 87, 87, 87, 91, 91, 86, 89, 97, 79, 79, 89, 77, 80, 82, 84, 87]\n",
      "[0, 28, 19, 26, 22, 25, 19, 23, 34, 31, 28, 16, 18, 21, 39, 24, 42, 41, 24, 47, 39, 30, 30, 30, 38, 32, 36, 21, 33, 26, 23, 21, 34, 22, 28, 25, 48, 32, 42, 29, 44, 33, 33, 39, 18, 30, 43, 30, 37, 29, 35, 24, 19, 20, 40, 15, 27, 32, 34, 31, 19, 22, 37, 18, 33, 25, 34, 34, 34, 30, 19, 14, 34, 18, 21, 20, 29, 35, 20, 24, 31, 37, 18, 25, 33, 21, 25, 14, 51, 39, 30, 27, 18, 27, 21, 27, 30, 27, 28, 28, 41]\n",
      "[0, 68, 59, 66, 62, 65, 59, 63, 74, 71, 68, 56, 58, 61, 79, 64, 82, 81, 64, 87, 79, 70, 70, 70, 78, 72, 76, 61, 73, 66, 63, 61, 74, 62, 68, 65, 88, 72, 82, 69, 84, 73, 73, 79, 58, 70, 83, 70, 77, 69, 75, 64, 59, 60, 80, 55, 67, 72, 74, 71, 59, 62, 77, 58, 73, 65, 74, 74, 74, 70, 59, 54, 74, 58, 61, 60, 69, 75, 60, 64, 71, 77, 58, 65, 73, 61, 65, 54, 91, 79, 70, 67, 58, 67, 61, 67, 70, 67, 68, 68, 81]\n"
     ]
    }
   ],
   "source": [
    "decode = lambda x: [tokenToVals[i] for i in x]\n",
    "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "print(decode(model.generate(context, max_new_tokens=100)[0].tolist()))\n",
    "\n",
    "def tokensToMidi(tokens):\n",
    "    vals = decode(tokens)\n",
    "    print(vals)\n",
    "    notes = []\n",
    "    for t in vals:\n",
    "        # print(type(t))\n",
    "        if(np.equal(t, 0)): continue\n",
    "        notes.append(t)\n",
    "    createMidiFileWithAllMessages(notes, filename='test.mid')\n",
    "\n",
    "\n",
    "gen1 = model.generate(context, max_new_tokens=100)[0].tolist()\n",
    "\n",
    "\n",
    "print(gen1)\n",
    "tokensToMidi(gen1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
