{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mido\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mido\n",
    "\n",
    "def createMidiFileWithAllMessages(notes, duration=200, wait_time = 0, filename='test.mid'):\n",
    "    mid = mido.MidiFile()\n",
    "    track = mido.MidiTrack()\n",
    "    mid.tracks.append(track)\n",
    "\n",
    "    for note in notes:\n",
    "        track.append(mido.Message('note_on', note=note, velocity=64, time=wait_time))\n",
    "        track.append(mido.Message('note_off', note=note, velocity=0, time=duration))\n",
    "\n",
    "    mid.save(filename.removesuffix('.mid') + '.mid')\n",
    "\n",
    "\n",
    "notes = range(50, 80) \n",
    "\n",
    "createMidiFileWithAllMessages(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "catch all the data\n",
      "['data\\\\chopin\\\\chpn-p1.mid', 'data\\\\chopin\\\\chpn-p10.mid', 'data\\\\chopin\\\\chpn-p11.mid', 'data\\\\chopin\\\\chpn-p12.mid', 'data\\\\chopin\\\\chpn-p13.mid', 'data\\\\chopin\\\\chpn-p14.mid', 'data\\\\chopin\\\\chpn-p15.mid', 'data\\\\chopin\\\\chpn-p16.mid', 'data\\\\chopin\\\\chpn-p17.mid', 'data\\\\chopin\\\\chpn-p18.mid']\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "print('catch all the data')\n",
    "\n",
    "def get_midis_one_artist(artist):\n",
    "    ms = []\n",
    "    directory = \"data\"\n",
    "    directory = os.path.join(\"data\", artist)\n",
    "    for filename in os.listdir(directory):\n",
    "        if('V2'in filename): continue\n",
    "        if os.path.isfile(os.path.join(directory, filename)):\n",
    "            ms.append(os.path.join(directory, filename))\n",
    "            # print(filename)\n",
    "    return ms\n",
    "\n",
    "\n",
    "def get_midis():\n",
    "    ms = []\n",
    "    directory = \"data\"\n",
    "    for foldername in os.listdir(directory):\n",
    "        directory = os.path.join(\"data\", foldername)\n",
    "        for filename in os.listdir(directory):\n",
    "            if('V2'in filename): continue\n",
    "            if os.path.isfile(os.path.join(directory, filename)):\n",
    "                ms.append(os.path.join(directory, filename))\n",
    "                # print(filename)\n",
    "    return ms\n",
    "\n",
    "# midis = get_midis()\n",
    "midis = get_midis_one_artist('chopin')\n",
    "print(midis[:10])\n",
    "# works only with files with just one track\n",
    "def get_all_notes_one_file(midi_file):\n",
    "    file = mido.MidiFile(midi_file)\n",
    "    track = file.tracks[1]\n",
    "    messages = []\n",
    "    for message in track:\n",
    "        if(message.type == 'note_on'):\n",
    "            messages.append(message)\n",
    "    \n",
    "    notes = [0] + [m.note for m in messages] + [1]\n",
    "    # print(notes)\n",
    "    return notes\n",
    "\n",
    "all_notes_all_files = [get_all_notes_one_file(m) for m in midis]\n",
    "\n",
    "print(len(all_notes_all_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80706,)\n",
      "notes extreme to remove :  [  0   1  26  28  29  33  34  35  36  37  38  39  40  41  42  43  44  45\n",
      "  46  47 101]\n",
      "[12 12 19 16 16 12 12 19 21 21]\n"
     ]
    }
   ],
   "source": [
    "X_values = np.concatenate(all_notes_all_files)\n",
    "print(X_values.shape)\n",
    "\n",
    "# notes\n",
    "\n",
    "n = np.unique(X_values, return_counts=True)\n",
    "notes_extreme = n[0][n[1] < 100]\n",
    "print('notes extreme to remove : ', notes_extreme)\n",
    "X_values = X_values[~np.isin(X_values, notes_extreme)]\n",
    "\n",
    "nunique = np.unique(X_values, return_counts=True)\n",
    "\n",
    "# Tokenize the data\n",
    "\n",
    "tokenToVals = nunique[0]\n",
    "\n",
    "ValsToToken = {v:i for i, v in enumerate(tokenToVals)}\n",
    "vocab_size = len(tokenToVals)\n",
    "\n",
    "X = np.array([ValsToToken[x] for x in X_values])\n",
    "a = np.random.randint(0, len(tokenToVals), 10)\n",
    "\n",
    "print(X[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "block_size = 128\n",
    "batch_size = 64\n",
    "n_embd = 192 # be a multiple of n_head\n",
    "dropout = 0.2\n",
    "n_heads = 6 # be a divisible of n_embd\n",
    "vocab_size = len(tokenToVals) # ~= 1800\n",
    "n_layer = 4\n",
    "eval_iters = 100\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([ValsToToken[x] for x in X_values], dtype=torch.long, device=device)\n",
    "n = int(0.9*len(X))\n",
    "X_train = X[:n]\n",
    "X_val = X[n:]\n",
    "\n",
    "# Single head self-attention\n",
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input of size (batch, time-step, channels)\n",
    "        # output of size (batch, time-step, head size)\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,hs)\n",
    "        q = self.query(x) # (B,T,hs)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,hs)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
    "        return out\n",
    "# multi-head self-attention\n",
    "class MultiHead(nn.Module):\n",
    "    \"\"\" multi-head self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, n_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(n_heads)])\n",
    "        self.proj = nn.Linear(n_heads * head_size, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # input of size (batch, time-step, channels)\n",
    "        # output of size (batch, time-step, channels)\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "# feed-forward layer\n",
    "class FeedForward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "    \n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, n_embd * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_embd * 4, n_embd),\n",
    "            nn.Dropout()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        return out\n",
    "# block\n",
    "class Block(nn.Module):\n",
    "    \"\"\" a transformer Block \"\"\"\n",
    "    \n",
    "    def __init__(self, n_embd, n_head):\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.MultiHeads = MultiHead(n_heads, head_size)\n",
    "        self.ffwd = FeedForward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.MultiHeads(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "# transformer\n",
    "class Transformer(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_heads) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd)\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "        \n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "        \n",
    "    def forward(self, idx, targets=None):\n",
    "        # print('oouais', idx.shape)\n",
    "        B, T = idx.shape\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        # pos_emb = self.position_embedding_table(torch.arange(T)) # (T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "    \n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -block_size:] # (B, T)\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "\n",
    "model = Transformer()\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = X_train if split == 'train' else X_val\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            # print(X.shape,Y.shape)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    # print(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "max_iters = 150000\n",
    "eval_interval = 500\n",
    "lossi = []\n",
    "learning_rate = 0.05\n",
    "best_val_loss = float('inf')\n",
    "stepBestVal = 0\n",
    "print(sum(p.numel() for p in model.parameters()), 'parameters')\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "# scheduler = lr_scheduler.StepLR(optimizer, step_size=2000, gamma=0.3)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10, verbose=True)\n",
    "# scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_iters, eta_min=0, last_epoch=-1)\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        lossi.append(losses)\n",
    "        # update the learning rate if the validation loss has stopped improving\n",
    "        if losses['val'] < best_val_loss:\n",
    "            stepBestVal = iter\n",
    "            best_val_loss = losses['val']\n",
    "            scheduler.step(losses['val'])\n",
    "        else:\n",
    "            scheduler.step(losses['val'])\n",
    "        \n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\\tlr : {optimizer.param_groups[0]['lr']}\\t best val loss : {best_val_loss:.4f}|at : {stepBestVal}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # scheduler.step()\n",
    "\n",
    "\n",
    "# save the model\n",
    "torch.save(model.state_dict(), 'model1.pth')\n",
    "\n",
    "print(lossi)\n",
    "plt.plot([l['train'] for l in lossi], label='train')\n",
    "plt.plot([l['val'] for l in lossi], label='val')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# converting it back to music\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode = lambda x: [tokenToVals[i] for i in x]\n",
    "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "print(decode(model.generate(context, max_new_tokens=100)[0].tolist()))\n",
    "\n",
    "def tokensToMidi(tokens):\n",
    "    vals = decode(tokens)\n",
    "    print(vals)\n",
    "    notes = []\n",
    "    for t in vals:\n",
    "        # print(type(t))\n",
    "        if(np.equal(t, 0)): continue\n",
    "        notes.append(t)\n",
    "    createMidiFileWithAllMessages(notes, filename='test.mid')\n",
    "\n",
    "\n",
    "gen1 = model.generate(context, max_new_tokens=100)[0].tolist()\n",
    "\n",
    "\n",
    "print(gen1)\n",
    "tokensToMidi(gen1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
